{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "We Achieved 0.883664 with this model at 69000 iterations (z value not number of epochs which is 47) \n",
    "\n",
    "Net Prameters:\n",
    "1. Batch size = 16 with shuffling but gradient update every four batches thus makig it viturally a btach size of 64\n",
    "\n",
    "2. Learning Rate = Dynamic using Adam\n",
    "\n",
    "3. Input dimensions = [-1,3,240,320]\n",
    "\n",
    "4. Output dimensions = [-1,4]          \n",
    "    ie.[batch_size,x1,y1,x2,y2]\n",
    "\n",
    "Image transformations:\n",
    "1. Resizing by half \n",
    "2. Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "import cv2\n",
    "\n",
    "torch.backends.cudnn.deterministic=True\n",
    "torch.cuda.manual_seed_all(999)\n",
    "torch.manual_seed(999)\n",
    "np.random.seed(999)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=\"model69000_batch_64_.pt\"\n",
    "RESULTS_FILE=\"results_model69000_batch_64__mach_1.csv\"\n",
    "BATCH_SIZE=16\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class FlipkartDataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.coords_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.coords_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.coords_frame.loc[idx,:][\"image_name\"])\n",
    "        image = cv2.imread(img_name)\n",
    "        image = cv2.resize(image, dsize=(320,240), interpolation=cv2.INTER_CUBIC)\n",
    "        image = cv2.normalize(image, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "        coords=[]\n",
    "        \n",
    "        coords=torch.tensor(np.array([self.coords_frame.loc[idx,:][\"x1\"],\n",
    "                self.coords_frame.loc[idx,:][\"y1\"],\n",
    "                self.coords_frame.loc[idx,:][\"x2\"],\n",
    "                self.coords_frame.loc[idx,:][\"y2\"]]))\n",
    "        \n",
    "        img_name= self.coords_frame.loc[idx,:][\"image_name\"]\n",
    "        X=dict({\"image\":image,\"name\":img_name})\n",
    "        y=coords\n",
    "        \n",
    "        return X,y\n",
    "    \n",
    "\n",
    "params = {'batch_size': BATCH_SIZE,\n",
    "          'shuffle': False}\n",
    "\n",
    "sampler=FlipkartDataset(\"Dataset/test.csv\",\"Dataset/images/\")\n",
    "testing_generator = data.DataLoader(sampler, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # input dim (3*240*320)\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=16, kernel_size=3)\n",
    "        self.conv1_bn = nn.BatchNorm2d(num_features=16)\n",
    "        # 16*240*320\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n",
    "        # 16*120*160\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3,)\n",
    "        self.conv2_bn = nn.BatchNorm2d(num_features=32)\n",
    "        # 32*120*160\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n",
    "        # 32*60*80\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3)\n",
    "        self.conv3_bn = nn.BatchNorm2d(num_features=64)\n",
    "        # 64*60*80\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n",
    "        # 64*30*40\n",
    "        \n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "        self.conv4_bn = nn.BatchNorm2d(num_features=128)\n",
    "        # 128*30*40\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2,padding=1)\n",
    "        # 128*15*20\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(128*15*20,2000)\n",
    "        self.fc2 = nn.Linear(2000, 1000)\n",
    "        self.fc3 = nn.Linear(1000, 500)\n",
    "        self.fc4 = nn.Linear(500, 4)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(self.conv1_bn(F.relu(self.conv1(x))))\n",
    "        x = self.pool2(self.conv2_bn(F.relu(self.conv2(x))))\n",
    "        x = self.pool3(self.conv3_bn(F.relu(self.conv3(x))))\n",
    "        x = self.pool4(self.conv4_bn(F.relu(self.conv4(x))))\n",
    "        #x = self.pool5(F.relu(self.conv5(x)))\n",
    "        #x = self.pool5(F.relu(self.conv5_bn(self.conv5(x))))\n",
    "        x = x.view(-1,128*15*20)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv1_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv4_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=38400, out_features=2000, bias=True)\n",
       "  (fc2): Linear(in_features=2000, out_features=1000, bias=True)\n",
       "  (fc3): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (fc4): Linear(in_features=500, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net=Net().cuda()\n",
    "\n",
    "checkpoint = torch.load(\"models/Mach_1/\"+MODEL)\n",
    "net.load_state_dict(checkpoint['state_dict'])\n",
    "net.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed: 24048 /24046\n",
      "Writing to  results_model69000_batch_64__mach_1.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_idx=list()\n",
    "x1_idx=list()\n",
    "y1_idx=list()\n",
    "x2_idx=list()\n",
    "y2_idx=list()\n",
    "\n",
    "\n",
    "z=0\n",
    "\n",
    "for X,y in testing_generator:\n",
    "    for each in X[\"name\"]:\n",
    "        img_idx.append(str(each))\n",
    "    X = X[\"image\"].type('torch.FloatTensor') \n",
    "    X=X.transpose(3,1)\n",
    "    X=X.transpose(2,3)\n",
    "    X=X.cuda()\n",
    "    \n",
    "    \n",
    "    output=net(X)\n",
    "    \n",
    "    for each in output:\n",
    "        x1_idx.append(int(each[0]))\n",
    "        y1_idx.append(int(each[1]))\n",
    "        x2_idx.append(int(each[2]))\n",
    "        y2_idx.append(int(each[3]))\n",
    "    \n",
    "    clear_output()\n",
    "    z+=BATCH_SIZE\n",
    "    print(\"Completed:\",z,\"/24046\")\n",
    "    \n",
    "print(\"Writing to \",RESULTS_FILE)\n",
    "grid=pd.DataFrame({\"image_name\":img_idx,\"x1\":x1_idx,\"x2\":x2_idx,\"y1\":y1_idx,\"y2\":y2_idx})\n",
    "grid.to_csv(RESULTS_FILE,index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
